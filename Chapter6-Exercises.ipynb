{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bac4ce7",
   "metadata": {},
   "source": [
    "## Assignment 6\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Exercise 6.1\n",
    "\n",
    "Consider the dataset from `data_banknote_authentication.csv`.\n",
    "\n",
    "1) Read data into a pandas dataframe.\n",
    "\n",
    "2) Pick the column named \"class\" as target variable `y` and all other columns as feature variables `X`.\n",
    "\n",
    "3) Split the data into training and testing sets with 80/20 ratio and `random_state=20`.\n",
    "\n",
    "4) Use support vector classifier with linear kernel to fit to the training data.\n",
    "\n",
    "5) Predict on the testing data and compute the confusion matrix and classification report.\n",
    "\n",
    "6) Repeat steps 3 and 4 for the radial basis function kernel.\n",
    "\n",
    "7) Compare the two SVM models in your own words.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Exercise 6.2\n",
    "\n",
    "This exercise is related to exercise 5.2 of the previous week. Consider the data from CSV file `weight-height.csv`.\n",
    "\n",
    "1) Read data into a pandas dataframe.\n",
    "\n",
    "2) Pick the target variable `y` as weight in kilograms, and the feature variable `X` as height in centimeters.\n",
    "\n",
    "3) Split the data into training and testing sets with 80/20 ratio.\n",
    "\n",
    "4) Scale the training and testing data using normalization and standardization.\n",
    "\n",
    "4) Fit a KNN regression model with `k=5` to the training data without scaling, predict on unscaled testing data and compute the $R^2$ value.\n",
    "\n",
    "6) Repeat step 4 for normalized data.\n",
    "\n",
    "7) Repeat step 4 for standardize data.\n",
    "\n",
    "8) Compare the models in terms of their $R^2$ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "734c6b46-d6fe-4993-bcf8-f5f194874492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM:\n",
      " [[152   2]\n",
      " [  0 121]] \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       154\n",
      "           1       0.98      1.00      0.99       121\n",
      "\n",
      "    accuracy                           0.99       275\n",
      "   macro avg       0.99      0.99      0.99       275\n",
      "weighted avg       0.99      0.99      0.99       275\n",
      "\n",
      "RBF SVM:\n",
      " [[154   0]\n",
      " [  0 121]] \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       154\n",
      "           1       1.00      1.00      1.00       121\n",
      "\n",
      "    accuracy                           1.00       275\n",
      "   macro avg       1.00      1.00      1.00       275\n",
      "weighted avg       1.00      1.00      1.00       275\n",
      "\n",
      "Linear is simpler and works well for linearly separable data; RBF can capture non-linear patterns and may perform better.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#1\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "#2\n",
    "df = pd.read_csv(\"data_banknote_authentication.csv\")\n",
    "X, y = df.drop(\"class\", axis=1), df[\"class\"]\n",
    "\n",
    "# 3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "\n",
    "# 4\n",
    "svm_linear = SVC(kernel=\"linear\").fit(X_train, y_train)\n",
    "y_pred_linear = svm_linear.predict(X_test)\n",
    "print(\"Linear SVM:\\n\", confusion_matrix(y_test, y_pred_linear), \"\\n\", classification_report(y_test, y_pred_linear))\n",
    "\n",
    "# 5\n",
    "svm_rbf = SVC(kernel=\"rbf\").fit(X_train, y_train)\n",
    "y_pred_rbf = svm_rbf.predict(X_test)\n",
    "print(\"RBF SVM:\\n\", confusion_matrix(y_test, y_pred_rbf), \"\\n\", classification_report(y_test, y_pred_rbf))\n",
    "\n",
    "# 6\n",
    "print(\"Linear is simpler and works well for linearly separable data; RBF can capture non-linear patterns and may perform better.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7b72ffc-5525-4c2f-933a-1453d72c6fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 without scaling: 0.8346\n",
      "R^2 with normalization: 0.8346\n",
      "R^2 with standardization: 0.8346\n",
      "\n",
      "Conclusion: Scaling usually improves KNN performance as it relies on distances.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 1 & 2\n",
    "df = pd.read_csv(\"weight-height.csv\")\n",
    "X = df[[\"Height\"]]\n",
    "y = df[\"Weight\"]\n",
    "\n",
    "# 3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "r2_no_scale = r2_score(y_test, y_pred)\n",
    "\n",
    "# 5\n",
    "scaler_norm = MinMaxScaler()\n",
    "X_train_norm = scaler_norm.fit_transform(X_train)\n",
    "X_test_norm = scaler_norm.transform(X_test)\n",
    "knn.fit(X_train_norm, y_train)\n",
    "y_pred_norm = knn.predict(X_test_norm)\n",
    "r2_norm = r2_score(y_test, y_pred_norm)\n",
    "\n",
    "# 6\n",
    "scaler_std = StandardScaler()\n",
    "X_train_std = scaler_std.fit_transform(X_train)\n",
    "X_test_std = scaler_std.transform(X_test)\n",
    "knn.fit(X_train_std, y_train)\n",
    "y_pred_std = knn.predict(X_test_std)\n",
    "r2_std = r2_score(y_test, y_pred_std)\n",
    "\n",
    "# 7\n",
    "print(f\"R^2 without scaling: {r2_no_scale:.4f}\")\n",
    "print(f\"R^2 with normalization: {r2_norm:.4f}\")\n",
    "print(f\"R^2 with standardization: {r2_std:.4f}\")\n",
    "print(\"\\nConclusion: Scaling usually improves KNN performance as it relies on distances.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21ee068-a2d7-4bf1-9639-b3f6ea5f39aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
